{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e634ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "DERMASON    3546\n",
      "SIRA        2636\n",
      "SEKER       2027\n",
      "HOROZ       1928\n",
      "CALI        1630\n",
      "BARBUNYA    1322\n",
      "BOMBAY       522\n",
      "Name: count, dtype: int64\n",
      "MLP - Confusion Matrix:\n",
      "[[296  22   0   1   2   6]\n",
      " [  8 342   0   3   1   5]\n",
      " [  0   0 950   3  10  36]\n",
      " [  0  10   3 302   0  15]\n",
      " [  3   0  11   0 345   6]\n",
      " [  2   0 102   4  14 677]]\n",
      "MLP - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       327\n",
      "           1       0.91      0.95      0.93       359\n",
      "           2       0.89      0.95      0.92       999\n",
      "           3       0.96      0.92      0.94       330\n",
      "           4       0.93      0.95      0.94       365\n",
      "           5       0.91      0.85      0.88       799\n",
      "\n",
      "    accuracy                           0.92      3179\n",
      "   macro avg       0.93      0.92      0.92      3179\n",
      "weighted avg       0.92      0.92      0.92      3179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "data = pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "data = data.dropna()\n",
    "\n",
    "data = pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "print(data['Class'].value_counts())\n",
    "\n",
    "# 1. 缺失值处理\n",
    "data = data.dropna()\n",
    "\n",
    "# 2. 异常值处理\n",
    "# 只选取数值型列进行异常值处理\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "Q1 = data[numeric_cols].quantile(0.25)\n",
    "Q3 = data[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 对数值型列进行过滤，非数值型列保持原值\n",
    "mask = ~((data[numeric_cols] < (Q1 - 1.5 * IQR)) | (data[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "data = data[mask]\n",
    "\n",
    "# 定义特征和目标变量\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# 对目标变量进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. 特征缩放 - 先使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. 特征缩放 - 使用 MinMaxScaler 进行归一化\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalized = min_max_scaler.fit_transform(X_train_scaled)\n",
    "X_test_normalized = min_max_scaler.transform(X_test_scaled)\n",
    "\n",
    "# 创建 PyTorch 数据集和数据加载器\n",
    "X_train_tensor = torch.FloatTensor(X_train_normalized)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test_normalized)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "input_size = X_train_normalized.shape[1]\n",
    "num_classes = len(set(y))\n",
    "\n",
    "# 创建模型、损失函数和优化器\n",
    "model = MLP(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.tolist())\n",
    "        y_true.extend(targets.tolist())\n",
    "\n",
    "# 输出结果\n",
    "print(\"MLP - Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"MLP - Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
